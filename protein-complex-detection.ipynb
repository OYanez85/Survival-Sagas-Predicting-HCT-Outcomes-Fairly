{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84969,"databundleVersionId":10033515,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install zarr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:50:38.642590Z","iopub.execute_input":"2024-12-18T19:50:38.643178Z","iopub.status.idle":"2024-12-18T19:50:51.539930Z","shell.execute_reply.started":"2024-12-18T19:50:38.643123Z","shell.execute_reply":"2024-12-18T19:50:51.538549Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: zarr in /opt/conda/lib/python3.10/site-packages (2.18.3)\nRequirement already satisfied: asciitree in /opt/conda/lib/python3.10/site-packages (from zarr) (0.3.3)\nRequirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from zarr) (1.26.4)\nRequirement already satisfied: numcodecs>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from zarr) (0.13.1)\nRequirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr) (0.19)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Standard libraries\nimport os\nimport json\n\n# Third-party libraries\nimport zarr\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# TensorFlow/Keras imports\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input,\n    Conv3D,\n    MaxPooling3D,\n    UpSampling3D,\n    Concatenate,\n    ZeroPadding3D,\n    Cropping3D\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:50:51.542769Z","iopub.execute_input":"2024-12-18T19:50:51.543821Z","iopub.status.idle":"2024-12-18T19:51:02.214017Z","shell.execute_reply.started":"2024-12-18T19:50:51.543761Z","shell.execute_reply":"2024-12-18T19:51:02.212760Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- Paths ---\nROOT_DIR = \"/kaggle/input/czii-cryo-et-object-identification\"\nTRAIN_DIR = os.path.join(ROOT_DIR, \"train/static/ExperimentRuns\")\nTRAIN_LABELS_DIR = os.path.join(ROOT_DIR, \"train/overlay/ExperimentRuns\")\nTEST_DIR = os.path.join(ROOT_DIR, \"test/static/ExperimentRuns\")\nSUBMISSION_PATH = \"submission.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.215259Z","iopub.execute_input":"2024-12-18T19:51:02.215973Z","iopub.status.idle":"2024-12-18T19:51:02.222040Z","shell.execute_reply.started":"2024-12-18T19:51:02.215935Z","shell.execute_reply":"2024-12-18T19:51:02.220900Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_zarr(filepath):\n    \"\"\"Load a Zarr file and return the highest resolution data.\"\"\"\n    if not os.path.exists(filepath):\n        print(f\"Zarr file not found: {filepath}\")\n        return None\n    zarr_file = zarr.open(filepath, mode='r')\n    return zarr_file[\"0\"]  # Level 0 has the highest resolution\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.224818Z","iopub.execute_input":"2024-12-18T19:51:02.225211Z","iopub.status.idle":"2024-12-18T19:51:02.238397Z","shell.execute_reply.started":"2024-12-18T19:51:02.225178Z","shell.execute_reply":"2024-12-18T19:51:02.237215Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_ground_truth(filepath):\n    \"\"\"Load ground truth particle coordinates from nested JSON.\"\"\"\n    if not os.path.exists(filepath):\n        print(f\"Ground truth file not found: {filepath}\")\n        return []\n    try:\n        with open(filepath, 'r') as f:\n            data = json.load(f)\n        points = data.get(\"points\", [])\n        coordinates = [[p['location']['x'], p['location']['y'], p['location']['z']]\n                       for p in points if 'location' in p]\n        return np.array(coordinates)\n    except Exception as e:\n        print(f\"Error loading JSON file {filepath}: {e}\")\n        return []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.239852Z","iopub.execute_input":"2024-12-18T19:51:02.240311Z","iopub.status.idle":"2024-12-18T19:51:02.253115Z","shell.execute_reply.started":"2024-12-18T19:51:02.240275Z","shell.execute_reply":"2024-12-18T19:51:02.251900Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_volume(volume):\n    \"\"\"Normalize and reshape the 3D volume.\"\"\"\n    if volume is None:\n        return None\n    volume = volume / np.max(volume)\n    return np.expand_dims(volume, axis=-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.254425Z","iopub.execute_input":"2024-12-18T19:51:02.254749Z","iopub.status.idle":"2024-12-18T19:51:02.265211Z","shell.execute_reply.started":"2024-12-18T19:51:02.254709Z","shell.execute_reply":"2024-12-18T19:51:02.263990Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def align_shapes(tensor1, tensor2):\n    \"\"\"Align shapes for concatenation using Cropping3D or ZeroPadding3D.\"\"\"\n    shape1 = tensor1.shape[1:4]  # Static shapes in Keras\n    shape2 = tensor2.shape[1:4]\n\n    cropping = []\n    padding = []\n\n    for s1, s2 in zip(shape1, shape2):\n        diff = s1 - s2\n        if diff > 0:  # Crop tensor1\n            cropping.append((diff // 2, diff - diff // 2))\n            padding.append((0, 0))  # No padding needed for tensor2\n        elif diff < 0:  # Pad tensor2\n            cropping.append((0, 0))  # No cropping needed for tensor1\n            padding.append((-diff // 2, -diff - (-diff // 2)))\n        else:\n            cropping.append((0, 0))\n            padding.append((0, 0))\n\n    # Apply Cropping3D or ZeroPadding3D\n    if any(c[0] > 0 or c[1] > 0 for c in cropping):\n        tensor1 = Cropping3D(cropping=cropping)(tensor1)\n    if any(p[0] > 0 or p[1] > 0 for p in padding):\n        tensor2 = ZeroPadding3D(padding=padding)(tensor2)\n\n    return tensor1, tensor2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.266788Z","iopub.execute_input":"2024-12-18T19:51:02.267178Z","iopub.status.idle":"2024-12-18T19:51:02.278071Z","shell.execute_reply.started":"2024-12-18T19:51:02.267144Z","shell.execute_reply":"2024-12-18T19:51:02.276604Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def crop_tensor(tensor, target_shape):\n    \"\"\"Crop a tensor to match the target shape.\"\"\"\n    cropping = [(0, 0)]  # For batch dimension\n    for dim, (src, tgt) in enumerate(zip(tensor.shape[1:4], target_shape[1:4])):\n        crop_size = src - tgt\n        if crop_size > 0:\n            cropping.append((crop_size // 2, crop_size - crop_size // 2))\n        else:\n            cropping.append((0, 0))\n    return Cropping3D(cropping=cropping[1:])(tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.279799Z","iopub.execute_input":"2024-12-18T19:51:02.280282Z","iopub.status.idle":"2024-12-18T19:51:02.296056Z","shell.execute_reply.started":"2024-12-18T19:51:02.280232Z","shell.execute_reply":"2024-12-18T19:51:02.294814Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def unet_3d(input_shape):\n    \"\"\"3D U-Net model with corrected shape alignment for concatenation.\"\"\"\n    inputs = Input(shape=input_shape)\n\n    # Encoder\n    conv1 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(inputs)\n    pool1 = MaxPooling3D((2, 2, 2))(conv1)\n\n    conv2 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(pool1)\n    pool2 = MaxPooling3D((2, 2, 2))(conv2)\n\n    # Bottleneck\n    conv3 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool2)\n\n    # Decoder\n    up2 = UpSampling3D((2, 2, 2))(conv3)\n    cropped_conv2 = crop_tensor(conv2, up2.shape)\n    concat2 = Concatenate()([cropped_conv2, up2])\n\n    conv4 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(concat2)\n    up1 = UpSampling3D((2, 2, 2))(conv4)\n    cropped_conv1 = crop_tensor(conv1, up1.shape)\n    concat1 = Concatenate()([cropped_conv1, up1])\n\n    conv5 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(concat1)\n    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid')(conv5)\n\n    return Model(inputs, outputs)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.297676Z","iopub.execute_input":"2024-12-18T19:51:02.298185Z","iopub.status.idle":"2024-12-18T19:51:02.312712Z","shell.execute_reply.started":"2024-12-18T19:51:02.298137Z","shell.execute_reply":"2024-12-18T19:51:02.311378Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def load_data(train_dir, labels_dir):\n    \"\"\"Load training data and corresponding labels.\"\"\"\n    X, Y = [], []\n    experiments = [exp for exp in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, exp))]\n\n    for exp in experiments:\n        volume_path = os.path.join(train_dir, exp, \"VoxelSpacing10.000\", \"denoised.zarr\")\n        labels_dir_path = os.path.join(labels_dir, exp, \"Picks\")\n\n        if not os.path.exists(volume_path) or not os.path.exists(labels_dir_path):\n            continue\n\n        print(f\"Loading volume from: {volume_path}\")\n        volume = load_zarr(volume_path)\n        volume = preprocess_volume(volume)\n        if volume is None:\n            continue\n\n        experiment_labels = []\n        for file in os.listdir(labels_dir_path):\n            if file.endswith(\".json\"):\n                particle_path = os.path.join(labels_dir_path, file)\n                labels = load_ground_truth(particle_path)\n                experiment_labels.extend(labels)\n\n        if len(experiment_labels) > 0:\n            X.append(volume)\n            Y.append(experiment_labels)\n    print(f\"Total Loaded: {len(X)} volumes and {len(Y)} label sets.\")\n    return np.array(X), Y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.316199Z","iopub.execute_input":"2024-12-18T19:51:02.316641Z","iopub.status.idle":"2024-12-18T19:51:02.332633Z","shell.execute_reply.started":"2024-12-18T19:51:02.316606Z","shell.execute_reply":"2024-12-18T19:51:02.331374Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def crop_to_match(y_true, y_pred):\n    \"\"\"Crop the target (y_true) to match the spatial dimensions of the prediction (y_pred).\"\"\"\n    target_shape = tf.shape(y_pred)[1:4]  # Get spatial dimensions of prediction\n    y_true_cropped = tf.image.resize_with_crop_or_pad(\n        y_true, target_shape[0], target_shape[1], target_shape[2]\n    )\n    return y_true_cropped","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.334049Z","iopub.execute_input":"2024-12-18T19:51:02.334535Z","iopub.status.idle":"2024-12-18T19:51:02.351295Z","shell.execute_reply.started":"2024-12-18T19:51:02.334480Z","shell.execute_reply":"2024-12-18T19:51:02.349987Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_model():\n    X, Y = load_data(TRAIN_DIR, TRAIN_LABELS_DIR)\n    if len(X) == 0:\n        raise ValueError(\"No training data loaded. Check file paths.\")\n    input_shape = X[0].shape\n\n    model = unet_3d(input_shape)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Placeholder binary masks (cropped to match model output)\n    predictions_shape = model.output_shape[1:]  # Get output shape\n    Y_masks = np.random.randint(0, 2, size=(len(X),) + predictions_shape)\n\n    # Fit model\n    model.fit(X, Y_masks, batch_size=1, epochs=5)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.352933Z","iopub.execute_input":"2024-12-18T19:51:02.353430Z","iopub.status.idle":"2024-12-18T19:51:02.364535Z","shell.execute_reply.started":"2024-12-18T19:51:02.353382Z","shell.execute_reply":"2024-12-18T19:51:02.363163Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def make_submission(model, test_dir, submission_path):\n    submission = []\n    experiments = [exp for exp in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, exp))]\n    idx = 0\n\n    for exp in experiments:\n        volume_path = os.path.join(test_dir, exp, \"VoxelSpacing10.000\", \"denoised.zarr\")\n        if not os.path.exists(volume_path):\n            continue\n\n        volume = load_zarr(volume_path)\n        volume = preprocess_volume(volume)\n        if volume is None:\n            continue\n\n        predictions = model.predict(np.expand_dims(volume, axis=0))\n        coords = np.argwhere(predictions > 0.5)\n\n        for coord in coords:\n            submission.append([idx, exp, \"unknown\", coord[0], coord[1], coord[2]])\n            idx += 1\n\n    df = pd.DataFrame(submission, columns=[\"id\", \"experiment\", \"particle_type\", \"x\", \"y\", \"z\"])\n    df.to_csv(submission_path, index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.366004Z","iopub.execute_input":"2024-12-18T19:51:02.366397Z","iopub.status.idle":"2024-12-18T19:51:02.382962Z","shell.execute_reply.started":"2024-12-18T19:51:02.366362Z","shell.execute_reply":"2024-12-18T19:51:02.381377Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    print(\"Training Model...\")\n    model = train_model()\n\n    print(\"Generating Submission...\")\n    make_submission(model, TEST_DIR, SUBMISSION_PATH)\n    print(\"Submission saved to:\", SUBMISSION_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:51:02.384380Z","iopub.execute_input":"2024-12-18T19:51:02.384714Z"}},"outputs":[{"name":"stdout","text":"Training Model...\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_86_3/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_6_6/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_6_4/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_5_4/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_73_6/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_99_9/VoxelSpacing10.000/denoised.zarr\nLoading volume from: /kaggle/input/czii-cryo-et-object-identification/train/static/ExperimentRuns/TS_69_2/VoxelSpacing10.000/denoised.zarr\nTotal Loaded: 7 volumes and 7 label sets.\nEpoch 1/5\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}