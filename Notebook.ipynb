{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lifelines","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T07:38:50.911413Z","iopub.execute_input":"2024-12-14T07:38:50.911712Z","iopub.status.idle":"2024-12-14T07:39:04.543835Z","shell.execute_reply.started":"2024-12-14T07:38:50.911686Z","shell.execute_reply":"2024-12-14T07:39:04.542881Z"}},"outputs":[{"name":"stdout","text":"Collecting lifelines\n  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (1.14.1)\nRequirement already satisfied: pandas>=2.1 in /opt/conda/lib/python3.10/site-packages (from lifelines) (2.2.3)\nRequirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.10/site-packages (from lifelines) (3.7.5)\nCollecting autograd>=1.5 (from lifelines)\n  Downloading autograd-1.7.0-py3-none-any.whl.metadata (7.5 kB)\nCollecting autograd-gamma>=0.3 (from lifelines)\n  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting formulaic>=0.2.2 (from lifelines)\n  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\nCollecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\nRequirement already satisfied: wrapt>=1.0 in /opt/conda/lib/python3.10/site-packages (from formulaic>=0.2.2->lifelines) (1.16.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.1->lifelines) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.1->lifelines) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\nDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading autograd-1.7.0-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=c0d4268df87f9b72db2878d5fe5fbfb0b1683e0051100d98b69bc5e629376f2d\n  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\nSuccessfully built autograd-gamma\nInstalling collected packages: interface-meta, autograd, autograd-gamma, formulaic, lifelines\nSuccessfully installed autograd-1.7.0 autograd-gamma-0.5.0 formulaic-1.0.2 interface-meta-1.3.0 lifelines-0.30.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom lifelines import CoxPHFitter\nfrom lifelines.utils import concordance_index\n\n# Load data\ntrain = pd.read_csv('/mnt/data/train.csv')\ntest = pd.read_csv('/mnt/data/test.csv')\ndata_dict = pd.read_csv('/mnt/data/data_dictionary.csv')\n\n# Quick data inspection\nprint(\"Train Data Shape:\", train.shape)\nprint(\"Test Data Shape:\", test.shape)\nprint(\"Columns in Train:\", train.columns)\n\n# Extract target variables\nevent_col = 'efs'\ntime_col = 'efs_time'\n\n# Preprocess the training data\n# Encode categorical variables\ncategorical_cols = train.select_dtypes(include=['object', 'category']).columns\nlabel_encoders = {}\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train[col] = train[col].fillna('Missing')\n    train[col] = le.fit_transform(train[col])\n    label_encoders[col] = le\n\n# Scale numerical variables\nnumerical_cols = train.select_dtypes(include=['float64', 'int64']).columns.drop([time_col])\nscaler = StandardScaler()\ntrain[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n\n# Stratified Concordance Index calculation\ndef stratified_c_index(df, risk_scores, time_col, event_col, stratify_col):\n    groups = df[stratify_col].unique()\n    c_indices = []\n\n    for group in groups:\n        group_data = df[df[stratify_col] == group]\n        c_index = concordance_index(group_data[time_col], risk_scores[group_data.index], group_data[event_col])\n        c_indices.append(c_index)\n\n    return np.mean(c_indices) - np.std(c_indices)\n\n# Prepare data for CoxPH model\nX = train.drop(columns=[time_col, event_col, 'race_group'])\ny = train[[time_col, event_col]]\n\ncox_model = CoxPHFitter()\ncox_model.fit(pd.concat([X, y], axis=1), duration_col=time_col, event_col=event_col)\n\n# Calculate risk scores and Stratified Concordance Index\ntrain['risk_score'] = cox_model.predict_partial_hazard(X)\nc_index_score = stratified_c_index(train, train['risk_score'], time_col, event_col, stratify_col='race_group')\n\nprint(\"Stratified Concordance Index on Train:\", c_index_score)\n\n# Preprocess test data\nfor col in categorical_cols:\n    test[col] = test[col].fillna('Missing')\n    test[col] = label_encoders[col].transform(test[col])\n\ntest[numerical_cols] = scaler.transform(test[numerical_cols])\n\n# Predict on test set\ntest['risk_score'] = cox_model.predict_partial_hazard(test)\nsubmission = test[['ID', 'risk_score']]\nsubmission.columns = ['ID', 'prediction']\n\n# Save submission file\nsubmission.to_csv('/mnt/data/submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}